---
title: "p8105_hw6_jak2312"
author: "Jared Klug"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
```

### Problem 1

```{r homicide_df}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

### Problem 2

```{r birthweight_df}

birthweight_df = read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace, labels = c("white", "black", "asian", "puerto_rican"))
  )

```

Start with model using all variables, then use stepwise regression automatic procedure using backward and forward selection to generate a more parisomious model. From the generated model, I'm also going to remove any variables that are directly related to the baby, i.e. baby's head circumference and baby's length at birth.
```{r lm_model}

model_fit = lm(bwt ~ ., data = birthweight_df)
step(model_fit, direction = "both")

gen_model = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_df)

hypoth_model = lm(bwt ~ babysex + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_df)

```

```{r model_summary}
hypoth_model %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "babysex", "Baby's Sex: "),
         term = str_replace(term, "mrace", "Mother's Race: ")) %>% 
  knitr::kable(digits = 3)
```

```{r model_diag}
birthweight_df %>% 
  modelr::add_predictions(hypoth_model) %>% 
  modelr::add_residuals(hypoth_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_line(y=0, color = "red")
```

```{r given_models}
given_1 = lm(bwt ~ blength + gaweeks, data = birthweight_df)

given_2 = lm(bwt ~ bhead * blength * babysex, data = birthweight_df)
```

```{r cross_val}
set.seed(1)
cv_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    my_mod = map(train, ~hypoth_model),
    given_mod_1 = map(train, ~given_1),
    given_mod_2 = map(train, ~given_2)
  ) %>% 
  mutate(
    rmse_my_mod = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_given_1 = map2_dbl(given_mod_1, test, ~rmse(model = .x, data = .y)),
    rmse_given_2 = map2_dbl(given_mod_2, test, ~rmse(model = .x, data = .y))
  )
```

```{r compare_models}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()
```

From this graph showing densities of the RMSE for each model, we can see that the given model 2 using head circumference, length, sex, and their interactions is the clear winner. My model had the largest RMSE values of the three models anecdotally showing that using automated approaches is not the ideal way to make model, but instead a way of reducing variables from a full model.